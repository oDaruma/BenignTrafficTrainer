{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fcb31daa",
   "metadata": {},
   "source": [
    "# Reflection: Applying Bayesian Optimisation (BO) to Network Intrusion Detection — **Benign-First Training for Non-Benign Identification**\n",
    "\n",
    "## Executive summary (non-technical)\n",
    "\n",
    "- **Goal.** Train detectors to **model benign traffic precisely** (high TNR) so we can **flag non-benign** whenever the model’s benign probability falls below a threshold τ. We **must** still maintain high attack detection (TPR ≥ 90%) and low latency on CPU. Corpora: **UNSW-NB15** and **CIC-IDS2017** labelled PCAPs. ([Kaggle][1], [UNSW Sites][2], [unb.ca][3])  \n",
    "- **Why BO.** BO **must** tune hyper-parameters, calibration, sampling ratios and τ under noisy/expensive evaluation with constraints (FPR cap, latency). It **should** prefer safe/constrained exploration and **may** reuse priors between datasets for sample efficiency. ([NeurIPS Proceedings][4], [arXiv][5], [PMC][6])  \n",
    "- **Outcome.** A CPU-deployable detector that **passes benign** (minimises false alerts) and **signals non-benign** reliably at a bounded **FPR** and **p95 latency**, with explainable outputs ready for SOC ingestion.\n",
    "\n",
    "---\n",
    "\n",
    "## 1) How the BO skills/code transfer (technical)\n",
    "\n",
    "### A. Direct applications (FN-aware but **benign-first** modelling)\n",
    "\n",
    "| BO skill | IDS use-case | **Optimisation target & constraints** | Key refs |\n",
    "| --- | --- | --- | --- |\n",
    "| GP surrogate + EI/UCB/KG | Hyper-parameter tuning (LightGBM/CatBoost/SGD, optional 1D-CNN) | **Objective:** maximise **TNR** (benign pass-rate). **Constraints:** **TPR ≥ 0.90**, **FPR ≤ 0.5%**, **p95 latency ≤ 10 ms**. Use **Noisy-EI**. | [4],[5] |\n",
    "| Noisy BO + replications | Stability under label noise & drift | 3–5× GroupKFold or repeated splits; fold variance → GP noise | [5] |\n",
    "| **Constrained / Safe BO** | Keep search within SOC limits | **SafeOpt/feasible filters:** reject configs violating latency/FPR constraints | [6],[7] |\n",
    "| Threshold & calibration BO | Operating point selection | Calibrate (Platt/Isotonic), then BO over τ with **FPR cap**; objective **TNR↑** under **TPR floor** | [5] |\n",
    "| Mixed discrete/continuous | End-to-end pipeline choice | Search over model family, class-weights, sampling, features | [4] |\n",
    "| Transfer/meta-BO | UNSW ↔ CIC generalisation | Warm-start from source dataset; compare TNR/TPR stability | [3] |\n",
    "\n",
    "**Why benign-first?** In production SIEM/SOAR, benign dominates. If the model **knows benign well**, anything that deviates (low benign probability) is a **non-benign candidate**. We still **must** uphold an attack-TPR floor to avoid missing true attacks.\n",
    "\n",
    "### B. What is optimised\n",
    "\n",
    "- **Features.** CICFlowMeter-style flow stats, byte histograms, temporal aggregates; **time-grouped** CV to avoid leakage. ([3],[8])  \n",
    "- **Models.** Baselines (SGD/LogReg), LightGBM/CatBoost; optional 1D-CNN on payload bytes if present.  \n",
    "- **Objective/constraints.** **Maximise TNR** under **TPR ≥ 0.90**, **FPR ≤ 0.5%**, **p95 latency ≤ 10 ms**.  \n",
    "- **Explainability.** SHAP stability on benign motifs; aide for triage playbooks.  \n",
    "\n",
    "---\n",
    "\n",
    "## 2) Questions addressed\n",
    "\n",
    "- **Benign pass-rate at fixed safety.** Which configurations yield **highest TNR** while keeping **TPR ≥ 0.90**, **FPR ≤ 0.5%**, **p95 latency ≤ 10 ms**?  \n",
    "- **Cross-dataset robustness.** Do UNSW-tuned τ and calibrations hold on CIC with acceptable TNR/TPR?  \n",
    "- **Alert budget discipline.** What benign false-alert reduction is achieved at the set FPR cap?  \n",
    "\n",
    "---\n",
    "\n",
    "## 3) Datasets\n",
    "\n",
    "- **Primary:** **UNSW-NB15 & CIC-IDS2017 Labelled PCAPs** (Kaggle/Zenodo). Integer matrices (e.g., **N×1504**) aligned to official CSVs. **Must** be used. ([1],[9])  \n",
    "- **Metadata:** **UNSW** official description; **CIC-IDS2017** official page; **CICFlowMeter** tooling. ([2],[3],[8])  \n",
    "\n",
    "**Splitting:** **GroupKFold by day/pcap/session** to prevent temporal leakage. UNSW↔CIC out-of-domain testing for generalisation.\n",
    "\n",
    "---\n",
    "\n",
    "## 4) Alignment\n",
    "\n",
    "- **SOC/DFIR (must).** High TNR reduces benign alert noise; TPR floor reduces missed attacks.  \n",
    "- **MLOps (should).** Constrained/safe BO, model cards, reproducible CV.  \n",
    "- **Deployment (must).** CPU latency bounds, τ at FPR cap, calibration stability.  \n",
    "\n",
    "---\n",
    "\n",
    "## Proposed project blueprint (updated)\n",
    "\n",
    "1. **Problem framing & KPIs (must).** **Objective:** maximise **TNR (benign pass-rate)**. **Constraints:** **TPR ≥ 0.90**, **FPR ≤ 0.5%**, **p95 latency ≤ 10 ms**; secondary: macro-F1, PR-AUC.  \n",
    "2. **Data engineering (must).** Load labelled PCAPs; derive flow/payload features; de-dup; **time-grouped CV**. ([1],[3])  \n",
    "3. **Model space (should).** SGD/LogReg; LightGBM/CatBoost; optional 1D-CNN (payload).  \n",
    "4. **BO setup (must).** GP-Matern(5/2) + **Noisy-EI**; batch 4–8; **feasibility filters** for FPR/latency/TPR. ([4],[5],[6])  \n",
    "5. **Imbalance handling (must).** BO over class-weights/sampling ratios with benign-first objective and TPR floor.  \n",
    "6. **Calibration & τ (should).** Platt vs Isotonic; τ picked under **FPR cap**.  \n",
    "7. **Cross-dataset (must).** UNSW↔CIC transfer; report ΔTNR/ΔTPR and τ drift.  \n",
    "8. **Explainability (may).** SHAP motifs → defensive heuristics/rules.  \n",
    "9. **Deployment (should).** CPU perf profile; CI job for small BO refresh on rolling data.  \n",
    "\n",
    "---\n",
    "\n",
    "## Kernel-crash avoidance & reliability controls\n",
    "\n",
    "- **Row cap for BO:** subsample to `MAX_TRAIN_ROWS` with stratification when datasets are huge.  \n",
    "- **Aggressive dtype down-cast & constant-column drop.**  \n",
    "- **Thread control:** limit OpenMP/BLAS threads to avoid oversubscription.  \n",
    "- **Safe plotting:** skip heavy skopt plots if memory constrained; free figures (`plt.close()`).  \n",
    "- **Checkpoint trials:** write a light **trials.parquet** to resume analysis after interruption.  \n",
    "- **Guard optional deps:** only search installed model families.  \n",
    "\n",
    "---\n",
    "\n",
    "## Explanation\n",
    "\n",
    "*We teach a computer what “normal (benign) internet traffic” looks like. If a new connection looks **unlike** benign, we treat it as **non-benign**.*\n",
    "\n",
    "1. We try different model settings. **Bayesian Optimisation** helps us *choose smartly* rather than guessing randomly.  \n",
    "2. We **calibrate** model scores so “0.8” really means “~80% chance benign”.  \n",
    "3. We pick a **threshold** (τ) so that **false alarms on normal traffic** stay under our limit.  \n",
    "4. We also check that **at least 90% of attacks** are still caught and that **predictions are fast** on a normal CPU.  \n",
    "5. We save the best settings and a small “model card” (a factsheet) for the SOC team.  \n",
    "\n",
    "---\n",
    "\n",
    "## Mathematical/statistical notes (used in code; quick glossary)\n",
    "\n",
    "- **Sigmoid:** maps any number to 0–1:  \\( \\sigma(z)=1/(1+e^{-z}) \\).  \n",
    "- **Calibration:** learn a mapping \\( g(p) \\) so calibrated probabilities match observed frequencies (Platt = logistic; Isotonic = monotone step-wise).  \n",
    "- **Confusion matrix:** TN/FP/FN/TP counts; **TNR** \\(= \\text{TN}/(\\text{TN}+\\text{FP})\\) (benign passed), **TPR** \\(= \\text{TP}/(\\text{TP}+\\text{FN})\\).  \n",
    "- **Percentiles:** p95 latency = time under which 95% of single-row predictions finish.  \n",
    "- **Bayesian Optimisation:** build a surrogate (GP with Matern-5/2 kernel) over hyper-params; pick next point by **Expected Improvement (EI)**; handle noise by modelling observation variance.  \n",
    "- **Feasible set:** we keep only configs with **TPR ≥ 0.90** and **latency ≤ 10 ms**; τ is chosen to satisfy **FPR cap**.  \n",
    "\n",
    "---\n",
    "\n",
    "[1]: https://www.kaggle.com/datasets/yasiralifarrukh/unsw-and-cicids2017-labelled-pcap-data/code?utm_source=chatgpt.com  \n",
    "[2]: https://research.unsw.edu.au/projects/unsw-nb15-dataset?utm_source=chatgpt.com  \n",
    "[3]: https://www.unb.ca/cic/datasets/ids-2017.html?utm_source=chatgpt.com  \n",
    "[4]: https://proceedings.neurips.cc/paper/2012/file/05311655a15b75fab86956663e1819cd-Paper.pdf?utm_source=chatgpt.com  \n",
    "[5]: https://arxiv.org/pdf/1807.02811?utm_source=chatgpt.com  \n",
    "[6]: https://pmc.ncbi.nlm.nih.gov/articles/PMC10485113/?utm_source=chatgpt.com  \n",
    "[7]: https://arxiv.org/abs/2403.12948?utm_source=chatgpt.com  \n",
    "[8]: https://github.com/ahlashkari/CICFlowMeter?utm_source=chatgpt.com  \n",
    "[9]: https://zenodo.org/records/7258579?utm_source=chatgpt.com  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b63dfe4",
   "metadata": {},
   "source": [
    "## 0) Imports & configuration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "259a6ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "import os, json, warnings, joblib\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import (\n",
    "    precision_recall_curve, average_precision_score, roc_auc_score,\n",
    "    confusion_matrix\n",
    ")\n",
    "from sklearn.model_selection import train_test_split, TimeSeriesSplit\n",
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "# HPO\n",
    "from skopt import BayesSearchCV, gp_minimize\n",
    "from skopt.space import Real, Integer\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "plt.rcParams[\"figure.figsize\"] = (7.5, 5)\n",
    "\n",
    "CSV_PATH     = \"archive/Payload_data_UNSW.csv\"\n",
    "ART_DIR      = \"ids_artifacts\"\n",
    "MODEL_PATH   = os.path.join(ART_DIR, \"model.pkl\")\n",
    "SCALER_PATH  = os.path.join(ART_DIR, \"scaler.pkl\")\n",
    "ENCODER_PATH = os.path.join(ART_DIR, \"label_encoder.pkl\")\n",
    "META_PATH    = os.path.join(ART_DIR, \"metadata.json\")\n",
    "TRIALS_PATH  = os.path.join(ART_DIR, \"trials.parquet\")\n",
    "\n",
    "Path(ART_DIR).mkdir(parents=True, exist_ok=True)\n",
    "Path(\"reports/figures\").mkdir(parents=True, exist_ok=True)\n",
    "Path(\"reports/tables\").mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80943d89",
   "metadata": {},
   "source": [
    "## 1. Problem & Data\n",
    "- **Task:** Model **benign** traffic; later, flag **non‑benign** if anomaly score ≥ τ.\n",
    "- **Metric for optimisation:** **AP (PR‑AUC)** on validation. (Attacks are rare → PR is more informative.)\n",
    "- **Dataset:** `archive/Payload_data_UNSW.csv` with binary `label` (0=benign, 1=non‑benign).\n",
    "- **Split (demo):** Stratified random train/val/test. In production, prefer **time‑based** or **grouped** splits.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5cd0a019",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shape: (79881, 1505)\n",
      "Unique string labels and counts:\n",
      "label_str\n",
      "normal            21000\n",
      "generic           17580\n",
      "exploits          13992\n",
      "fuzzers           12722\n",
      "reconnaissance     7562\n",
      "dos                3397\n",
      "backdoor           1239\n",
      "analysis           1208\n",
      "shellcode          1088\n",
      "worms                93\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Binary label balance (0=benign 'normal', 1=non-benign):\n",
      "label\n",
      "non-benign    0.737\n",
      "benign        0.263\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Splits → train: (51123, 1506) val: (12781, 1506) test: (15977, 1506)\n",
      "Train binary balance:\n",
      " label\n",
      "1    0.737\n",
      "0    0.263\n",
      "Name: proportion, dtype: float64\n",
      "Val   binary balance:\n",
      " label\n",
      "1    0.737\n",
      "0    0.263\n",
      "Name: proportion, dtype: float64\n",
      "Test  binary balance:\n",
      " label\n",
      "1    0.737\n",
      "0    0.263\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Feature shapes: (51123, 1503) (12781, 1503) (15977, 1503)\n",
      "Benign rows in train: 13440\n"
     ]
    }
   ],
   "source": [
    "# --- Load CSV ---\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "print(\"Original shape:\", df.shape)\n",
    "assert \"label\" in df.columns, \"Expected a 'label' column with string classes.\"\n",
    "\n",
    "# --- Preserve string labels, create binary label ---\n",
    "df = df.copy()\n",
    "df[\"label_str\"] = df[\"label\"].astype(str)\n",
    "\n",
    "# Map: benign = 'normal' -> 0, non-benign (everything else) -> 1\n",
    "df[\"label\"] = (df[\"label_str\"] != \"normal\").astype(int)\n",
    "\n",
    "# Quick checks\n",
    "print(\"Unique string labels and counts:\")\n",
    "print(df[\"label_str\"].value_counts())\n",
    "\n",
    "print(\"\\nBinary label balance (0=benign 'normal', 1=non-benign):\")\n",
    "print(df[\"label\"].value_counts(normalize=True).rename({0:\"benign\", 1:\"non-benign\"}).round(3))\n",
    "\n",
    "# Optional sanity check: no NaNs\n",
    "assert not df[\"label\"].isna().any(), \"Label has NaNs after mapping.\"\n",
    "\n",
    "# --- Stratified splits on the NEW binary label ---\n",
    "train_df, test_df = train_test_split(\n",
    "    df, test_size=0.2, random_state=42, stratify=df[\"label\"]\n",
    ")\n",
    "train_df, val_df  = train_test_split(\n",
    "    train_df, test_size=0.2, random_state=42, stratify=train_df[\"label\"]\n",
    ")\n",
    "\n",
    "print(\"\\nSplits → train:\", train_df.shape, \"val:\", val_df.shape, \"test:\", test_df.shape)\n",
    "print(\"Train binary balance:\\n\", train_df[\"label\"].value_counts(normalize=True).round(3))\n",
    "print(\"Val   binary balance:\\n\", val_df[\"label\"].value_counts(normalize=True).round(3))\n",
    "print(\"Test  binary balance:\\n\", test_df[\"label\"].value_counts(normalize=True).round(3))\n",
    "\n",
    "# (Re)build features with your existing helper, which drops 'label' automatically\n",
    "X_train = build_X(train_df, fit_scaler=True)\n",
    "X_val   = build_X(val_df,   fit_scaler=False)\n",
    "X_test  = build_X(test_df,  fit_scaler=False)\n",
    "\n",
    "y_train = train_df[\"label\"].values\n",
    "y_val   = val_df[\"label\"].values\n",
    "y_test  = test_df[\"label\"].values\n",
    "\n",
    "print(\"\\nFeature shapes:\", X_train.shape, X_val.shape, X_test.shape)\n",
    "\n",
    "# Benign-only subset for IF training (0 = benign 'normal')\n",
    "X_train_benign = X_train[y_train == 0]\n",
    "print(\"Benign rows in train:\", X_train_benign.shape[0])\n",
    "if X_train_benign.shape[0] == 0:\n",
    "    raise ValueError(\"Still no benign rows after mapping. Check the mapping or splits.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51ff1563",
   "metadata": {},
   "source": [
    "## 1.1 Quick diagnosis cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e3a58385",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall balance: {1: 58881, 0: 21000}\n",
      "Train balance: {1: 37683, 0: 13440}\n",
      "Val balance: {1: 9421, 0: 3360}\n",
      "Test balance: {1: 11777, 0: 4200}\n",
      "Using BENIGN_LABEL = 0\n"
     ]
    }
   ],
   "source": [
    "# Diagnose label distribution overall and per split\n",
    "print(\"Overall balance:\", df['label'].value_counts().to_dict())\n",
    "print(\"Train balance:\",  train_df['label'].value_counts().to_dict())\n",
    "print(\"Val balance:\",    val_df['label'].value_counts().to_dict())\n",
    "print(\"Test balance:\",   test_df['label'].value_counts().to_dict())\n",
    "\n",
    "# Choose the benign label automatically (0 by default; fall back to 1 if needed)\n",
    "BENIGN_LABEL = 0\n",
    "if (train_df['label'] == 0).sum() == 0 and (train_df['label'] == 1).sum() > 0:\n",
    "    BENIGN_LABEL = 1\n",
    "print(f\"Using BENIGN_LABEL = {BENIGN_LABEL}\")\n",
    "\n",
    "# If there are too few benign rows in train, re-split with different ratios\n",
    "MIN_BENIGN_TRAIN = 50  # tweak if needed\n",
    "if (train_df['label'] == BENIGN_LABEL).sum() < MIN_BENIGN_TRAIN:\n",
    "    print(\"Re-splitting to ensure enough benign rows in train...\")\n",
    "    # Try a smaller test/val to increase train size\n",
    "    tmp_train, tmp_test = train_test_split(\n",
    "        df, test_size=0.15, random_state=42, stratify=df['label']\n",
    "    )\n",
    "    tmp_train, tmp_val  = train_test_split(\n",
    "        tmp_train, test_size=0.15, random_state=42, stratify=tmp_train['label']\n",
    "    )\n",
    "    # Only adopt if it improves benign count\n",
    "    if (tmp_train['label'] == BENIGN_LABEL).sum() > (train_df['label'] == BENIGN_LABEL).sum():\n",
    "        train_df, val_df, test_df = tmp_train, tmp_val, tmp_test\n",
    "        print(\"Re-split applied.\")\n",
    "    else:\n",
    "        print(\"Re-split did not improve benign count; continuing with original split.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afaf4a7c",
   "metadata": {},
   "source": [
    "## 2. Features & Scaling (preprocessing summary)\n",
    "For a comparable, simple baseline we:\n",
    "- keep **numeric** columns only,\n",
    "- drop `label` from features,\n",
    "- use `StandardScaler` fit on **train**, then transform **val/test**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4c99d6e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Benign rows in train: 13440\n"
     ]
    }
   ],
   "source": [
    "# Rebuild features after potentially changing the splits\n",
    "X_train = build_X(train_df, fit_scaler=True)\n",
    "X_val   = build_X(val_df,   fit_scaler=False)\n",
    "X_test  = build_X(test_df,  fit_scaler=False)\n",
    "\n",
    "y_train = train_df[\"label\"].values\n",
    "y_val   = val_df[\"label\"].values\n",
    "y_test  = test_df[\"label\"].values\n",
    "\n",
    "# Safe benign-only selection (falls back if empty)\n",
    "benign_mask = (y_train == BENIGN_LABEL)\n",
    "num_benign  = int(benign_mask.sum())\n",
    "print(f\"Benign rows in train: {num_benign}\")\n",
    "\n",
    "if num_benign == 0:\n",
    "    # Last-resort fallback: treat entire train as \"unlabeled benign\" for unsupervised fitting.\n",
    "    # You’ll still evaluate on val/test with labels.\n",
    "    print(\"WARNING: No benign rows in train. Fitting IF on ALL training rows (unsupervised fallback).\")\n",
    "    X_train_benign = X_train\n",
    "else:\n",
    "    X_train_benign = X_train[benign_mask]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb6256cf",
   "metadata": {},
   "source": [
    "## 3. Baseline Model (Benign‑only Isolation Forest)\n",
    "Following the baseline → optimise pattern:\n",
    "- Train IF on **benign‑only** `X_train`.\n",
    "- Score = `−score_samples(X)` so **higher = more anomalous**.\n",
    "- Evaluate on **val/test** with PR curves and rank metrics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dda8834f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved baseline model → ids_artifacts/model.pkl\n",
      "Validation:\n",
      "[val_baseline] AP=0.8478 | ROC-AUC=0.7136 | P@127=0.9528 | R@127=0.0128\n",
      "Test:\n",
      "[test_baseline] AP=0.8479 | ROC-AUC=0.7157 | P@159=0.9308 | R@159=0.0126\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "X_train_benign = X_train[y_train == 0]\n",
    "\n",
    "base_if = IsolationForest(\n",
    "    n_estimators=300, max_samples=0.7, contamination=0.01, max_features=1.0,\n",
    "    random_state=42, n_jobs=-1\n",
    ").fit(X_train_benign)\n",
    "\n",
    "joblib.dump(base_if, MODEL_PATH)\n",
    "print(\"Saved baseline model →\", MODEL_PATH)\n",
    "\n",
    "def precision_at_k(y_true, scores, k):\n",
    "    idx = np.argsort(scores)[::-1][:k]\n",
    "    return (y_true[idx] == 1).mean()\n",
    "\n",
    "def recall_at_k(y_true, scores, k):\n",
    "    idx = np.argsort(scores)[::-1][:k]\n",
    "    tp = (y_true[idx] == 1).sum()\n",
    "    positives = (y_true == 1).sum()\n",
    "    return tp / positives if positives > 0 else 0.0\n",
    "\n",
    "def eval_split(name, model, X, y):\n",
    "    scores = -model.score_samples(X)\n",
    "    ap  = average_precision_score(y, scores)\n",
    "    roc = roc_auc_score(y, scores)\n",
    "    p, r, _ = precision_recall_curve(y, scores)\n",
    "    plt.figure(); plt.plot(r, p); plt.xlabel(\"Recall\"); plt.ylabel(\"Precision\")\n",
    "    plt.title(f\"PR Curve — {name} (AP={ap:.3f})\"); plt.tight_layout()\n",
    "    plt.savefig(f\"reports/figures/pr_{name}.png\", dpi=130); plt.close()\n",
    "    k = min(1000, max(1, int(0.01 * len(scores))))\n",
    "    print(f\"[{name}] AP={ap:.4f} | ROC-AUC={roc:.4f} | P@{k}={precision_at_k(y, scores, k):.4f} | R@{k}={recall_at_k(y, scores, k):.4f}\")\n",
    "    pd.DataFrame({\"score\": scores, \"label\": y}).to_csv(f\"reports/tables/scores_{name}.csv\", index=False)\n",
    "    return ap, roc\n",
    "\n",
    "print(\"Validation:\"); _ = eval_split(\"val_baseline\", base_if, X_val, y_val)\n",
    "print(\"Test:\");       _ = eval_split(\"test_baseline\", base_if, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a02a4c01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique labels in dataset: (array([0, 1]), array([21000, 58881]))\n",
      "Train unique: (array([0, 1]), array([13440, 37683]))\n",
      "Val unique: (array([0, 1]), array([3360, 9421]))\n",
      "Test unique: (array([0, 1]), array([ 4200, 11777]))\n",
      "Any NaNs in label? 0\n",
      "Numeric feature count: 1503\n"
     ]
    }
   ],
   "source": [
    "print(\"Unique labels in dataset:\", np.unique(df['label'].values, return_counts=True))\n",
    "print(\"Train unique:\", np.unique(y_train, return_counts=True))\n",
    "print(\"Val unique:\",   np.unique(y_val, return_counts=True))\n",
    "print(\"Test unique:\",  np.unique(y_test, return_counts=True))\n",
    "print(\"Any NaNs in label?\", df['label'].isna().sum())\n",
    "print(\"Numeric feature count:\", build_X(df).shape[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09ee8264",
   "metadata": {},
   "source": [
    "## 4. Hyperparameter Search Space\n",
    "Define ranges before random/BO search.\n",
    "For IF we tune **4 dials**:\n",
    "- `n_estimators` ∈ [100, 800], `max_samples` ∈ [0.3, 1.0],\n",
    "- `contamination` ∈ [1e‑3, 2e‑2] (log‑uniform), `max_features` ∈ [0.5, 1.0]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8eb625f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "SPACE = dict(\n",
    "    n_estimators=(100, 800),\n",
    "    max_samples=(0.3, 1.0),\n",
    "    contamination=(0.001, 0.02),\n",
    "    max_features=(0.5, 1.0),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13b4d9d0",
   "metadata": {},
   "source": [
    "## 5. Automated HPO — Random Search (baseline to beat)\n",
    "We first run a **simple random search**:\n",
    "1) Sample params → fit on **benign train**.\n",
    "2) Score **AP on validation**.\n",
    "3) Track **best** and keep a trials table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f88d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "def random_search_if(X_train_b, X_val, y_val, n_iter=30, seed=42):\n",
    "    rng = np.random.RandomState(seed)\n",
    "    trials, best = [], (-np.inf, None)\n",
    "    for i in range(n_iter):\n",
    "        params = {\n",
    "            \"n_estimators\": rng.randint(SPACE[\"n_estimators\"][0], SPACE[\"n_estimators\"][1] + 1),\n",
    "            \"max_samples\":  rng.uniform(*SPACE[\"max_samples\"]),\n",
    "            \"contamination\": 10 ** rng.uniform(np.log10(SPACE[\"contamination\"][0]), np.log10(SPACE[\"contamination\"][1])),\n",
    "            \"max_features\": rng.uniform(*SPACE[\"max_features\"]),\n",
    "            \"random_state\": 42, \"n_jobs\": -1\n",
    "        }\n",
    "        m = IsolationForest(**params).fit(X_train_b)\n",
    "        ap = average_precision_score(y_val, -m.score_samples(X_val))\n",
    "        trials.append({**params, \"AP\": ap})\n",
    "        if ap > best[0]: best = (ap, params)\n",
    "        print(f\"Iter {i+1}/{n_iter} | AP={ap:.4f} | {params}\")\n",
    "    tdf = pd.DataFrame(trials)\n",
    "    tdf.to_parquet(TRIALS_PATH, index=False)\n",
    "    print(\"Saved trials →\", TRIALS_PATH)\n",
    "    return best, tdf\n",
    "\n",
    "best_rs, trials_rs = random_search_if(X_train_benign, X_val, y_val, n_iter=30)\n",
    "print(\"Best Random Search AP:\", round(best_rs[0], 4)); print(\"Best params:\", best_rs[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e72b315d",
   "metadata": {},
   "source": [
    "## 6. Bayesian Optimisation with Scikit‑Optimize — `BayesSearchCV`\n",
    "Search that **learns** where to try next.\n",
    "We wrap IF so the scorer uses anomaly scores to compute **AP** in CV folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f95717",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DATA] Loading CSV from: archive/Payload_data_UNSW.csv\n",
      "[DATA] Dropped 25 constant columns.\n",
      "[DATA] Done. Features shape: (79881, 1479), Labels: (79881,)\n",
      "[SPLIT] Train: (59910, 1479)  Test: (19971, 1479)\n",
      "[BO] Setup: n_calls=30, n_initial_points=10, acq=EI\n",
      "[BO] Starting Bayesian Optimisation…\n",
      "[CNN] Epoch 1/6 - avg loss: 0.6629\n",
      "[CNN] Epoch 2/6 - avg loss: 0.6003\n",
      "[CNN] Epoch 3/6 - avg loss: 0.5828\n",
      "[CNN] Epoch 4/6 - avg loss: 0.5788\n",
      "[CNN] Epoch 5/6 - avg loss: 0.5771\n",
      "[CNN] Epoch 6/6 - avg loss: 0.5761\n",
      "[CNN] Epoch 1/6 - avg loss: 0.5758\n",
      "[CNN] Epoch 2/6 - avg loss: 0.5748\n",
      "[CNN] Epoch 3/6 - avg loss: 0.5733\n",
      "[CNN] Epoch 4/6 - avg loss: 0.5727\n",
      "[CNN] Epoch 5/6 - avg loss: 0.5720\n",
      "[CNN] Epoch 6/6 - avg loss: 0.5706\n",
      "[CNN] Epoch 1/6 - avg loss: 0.5684\n",
      "[CNN] Epoch 2/6 - avg loss: 0.5672\n",
      "[CNN] Epoch 3/6 - avg loss: 0.5665\n",
      "[CNN] Epoch 4/6 - avg loss: 0.5658\n",
      "[CNN] Epoch 5/6 - avg loss: 0.5646\n",
      "[CNN] Epoch 6/6 - avg loss: 0.5641\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "Early stopping, best iteration is:\n",
      "[517]\tvalid_0's binary_logloss: 0.00842418\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[612]\tvalid_0's binary_logloss: 0.00427904\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[600]\tvalid_0's binary_logloss: 0.00673026\n",
      "[BO] Trial 5: model=sgd, calib=platt\n",
      "[BO] Trial 10: model=cat, calib=isotonic\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[501]\tvalid_0's binary_logloss: 0.177288\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[501]\tvalid_0's binary_logloss: 0.178249\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[501]\tvalid_0's binary_logloss: 0.177747\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[566]\tvalid_0's binary_logloss: 0.0269437\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[566]\tvalid_0's binary_logloss: 0.0268058\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[566]\tvalid_0's binary_logloss: 0.0289145\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[586]\tvalid_0's binary_logloss: 0.000595944\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "Early stopping, best iteration is:\n",
      "[125]\tvalid_0's binary_logloss: 0.00288386\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[586]\tvalid_0's binary_logloss: 0.000503804\n",
      "[BO] Trial 15: model=lgbm, calib=platt\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[235]\tvalid_0's binary_logloss: 0.410234\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[235]\tvalid_0's binary_logloss: 0.410525\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[235]\tvalid_0's binary_logloss: 0.410051\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "Early stopping, best iteration is:\n",
      "[362]\tvalid_0's binary_logloss: 0.00437889\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "Early stopping, best iteration is:\n",
      "[177]\tvalid_0's binary_logloss: 0.00506763\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "Early stopping, best iteration is:\n",
      "[530]\tvalid_0's binary_logloss: 0.00718029\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "Early stopping, best iteration is:\n",
      "[79]\tvalid_0's binary_logloss: 0.00430061\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "Early stopping, best iteration is:\n",
      "[56]\tvalid_0's binary_logloss: 0.00450372\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "Early stopping, best iteration is:\n",
      "[91]\tvalid_0's binary_logloss: 0.0095663\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[200]\tvalid_0's binary_logloss: 0.439781\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[200]\tvalid_0's binary_logloss: 0.440125\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[200]\tvalid_0's binary_logloss: 0.439284\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[357]\tvalid_0's binary_logloss: 0.0316103\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[357]\tvalid_0's binary_logloss: 0.0334822\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[357]\tvalid_0's binary_logloss: 0.0324127\n",
      "[BO] Trial 20: model=lgbm, calib=platt\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[492]\tvalid_0's binary_logloss: 0.138771\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[492]\tvalid_0's binary_logloss: 0.137908\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[492]\tvalid_0's binary_logloss: 0.137826\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "Early stopping, best iteration is:\n",
      "[111]\tvalid_0's binary_logloss: 0.00415546\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "Early stopping, best iteration is:\n",
      "[155]\tvalid_0's binary_logloss: 0.00250921\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "Early stopping, best iteration is:\n",
      "[89]\tvalid_0's binary_logloss: 0.00373598\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Fatal] Cannot use bagging in GOSS\n"
     ]
    },
    {
     "ename": "LightGBMError",
     "evalue": "Cannot use bagging in GOSS",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mLightGBMError\u001b[39m                             Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      3\u001b[39m X_train, X_test, y_train, y_test = train_test_split(\n\u001b[32m      4\u001b[39m     X_full, y_full, test_size=\u001b[32m0.25\u001b[39m, random_state=SEED, stratify=y_full\n\u001b[32m      5\u001b[39m )\n\u001b[32m      6\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m[SPLIT] Train:\u001b[39m\u001b[33m\"\u001b[39m, X_train.shape, \u001b[33m\"\u001b[39m\u001b[33m Test:\u001b[39m\u001b[33m\"\u001b[39m, X_test.shape)\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m bo_out = run_constrained_bo_skos(X_train, y_train, n_calls=\u001b[32m30\u001b[39m, n_initial_points=\u001b[32m10\u001b[39m, random_state=SEED, make_plots=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m      9\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m=== BO Best (benign-first objective; multiclass training) ===\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     10\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mParams:\u001b[39m\u001b[33m\"\u001b[39m, bo_out.best_params)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 245\u001b[39m, in \u001b[36mrun_constrained_bo_skos\u001b[39m\u001b[34m(X, Y, n_calls, n_initial_points, random_state, make_plots)\u001b[39m\n\u001b[32m    242\u001b[39m _TRIAL_COUNT = {\u001b[33m\"\u001b[39m\u001b[33mn\u001b[39m\u001b[33m\"\u001b[39m: \u001b[32m0\u001b[39m}\n\u001b[32m    244\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m[BO] Setup: n_calls=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_calls\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, n_initial_points=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_initial_points\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, acq=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00macq_func\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m245\u001b[39m res = gp_minimize(\n\u001b[32m    246\u001b[39m     func=objective,\n\u001b[32m    247\u001b[39m     dimensions=space,\n\u001b[32m    248\u001b[39m     n_calls=\u001b[38;5;28mint\u001b[39m(n_calls),\n\u001b[32m    249\u001b[39m     n_initial_points=\u001b[38;5;28mint\u001b[39m(n_initial_points),\n\u001b[32m    250\u001b[39m     acq_func=acq_func,\n\u001b[32m    251\u001b[39m     noise=\u001b[33m\"\u001b[39m\u001b[33mgaussian\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    252\u001b[39m     random_state=\u001b[38;5;28mint\u001b[39m(random_state),\n\u001b[32m    253\u001b[39m     n_restarts_optimizer=\u001b[38;5;28mint\u001b[39m(n_restarts_optimizer)\n\u001b[32m    254\u001b[39m )\n\u001b[32m    255\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m[BO] Finished.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    257\u001b[39m best_params = {dim.name: val \u001b[38;5;28;01mfor\u001b[39;00m dim, val \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(space, res.x)}\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/py312/lib/python3.12/site-packages/skopt/optimizer/gp.py:281\u001b[39m, in \u001b[36mgp_minimize\u001b[39m\u001b[34m(func, dimensions, base_estimator, n_calls, n_random_starts, n_initial_points, initial_point_generator, acq_func, acq_optimizer, x0, y0, random_state, verbose, callback, n_points, n_restarts_optimizer, xi, kappa, noise, n_jobs, model_queue_size, space_constraint)\u001b[39m\n\u001b[32m    273\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m base_estimator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    274\u001b[39m     base_estimator = cook_estimator(\n\u001b[32m    275\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mGP\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    276\u001b[39m         space=space,\n\u001b[32m    277\u001b[39m         random_state=rng.randint(\u001b[32m0\u001b[39m, np.iinfo(np.int32).max),\n\u001b[32m    278\u001b[39m         noise=noise,\n\u001b[32m    279\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m281\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m base_minimize(\n\u001b[32m    282\u001b[39m     func,\n\u001b[32m    283\u001b[39m     space,\n\u001b[32m    284\u001b[39m     base_estimator=base_estimator,\n\u001b[32m    285\u001b[39m     acq_func=acq_func,\n\u001b[32m    286\u001b[39m     xi=xi,\n\u001b[32m    287\u001b[39m     kappa=kappa,\n\u001b[32m    288\u001b[39m     acq_optimizer=acq_optimizer,\n\u001b[32m    289\u001b[39m     n_calls=n_calls,\n\u001b[32m    290\u001b[39m     n_points=n_points,\n\u001b[32m    291\u001b[39m     n_random_starts=n_random_starts,\n\u001b[32m    292\u001b[39m     n_initial_points=n_initial_points,\n\u001b[32m    293\u001b[39m     initial_point_generator=initial_point_generator,\n\u001b[32m    294\u001b[39m     n_restarts_optimizer=n_restarts_optimizer,\n\u001b[32m    295\u001b[39m     x0=x0,\n\u001b[32m    296\u001b[39m     y0=y0,\n\u001b[32m    297\u001b[39m     random_state=rng,\n\u001b[32m    298\u001b[39m     verbose=verbose,\n\u001b[32m    299\u001b[39m     space_constraint=space_constraint,\n\u001b[32m    300\u001b[39m     callback=callback,\n\u001b[32m    301\u001b[39m     n_jobs=n_jobs,\n\u001b[32m    302\u001b[39m     model_queue_size=model_queue_size,\n\u001b[32m    303\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/py312/lib/python3.12/site-packages/skopt/optimizer/base.py:332\u001b[39m, in \u001b[36mbase_minimize\u001b[39m\u001b[34m(func, dimensions, base_estimator, n_calls, n_random_starts, n_initial_points, initial_point_generator, acq_func, acq_optimizer, x0, y0, random_state, verbose, callback, n_points, n_restarts_optimizer, xi, kappa, n_jobs, model_queue_size, space_constraint)\u001b[39m\n\u001b[32m    330\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_calls):\n\u001b[32m    331\u001b[39m     next_x = optimizer.ask()\n\u001b[32m--> \u001b[39m\u001b[32m332\u001b[39m     next_y = func(next_x)\n\u001b[32m    333\u001b[39m     result = optimizer.tell(next_x, next_y)\n\u001b[32m    334\u001b[39m     result.specs = specs\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/py312/lib/python3.12/site-packages/skopt/utils.py:779\u001b[39m, in \u001b[36muse_named_args.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(x)\u001b[39m\n\u001b[32m    776\u001b[39m arg_dict = {dim.name: value \u001b[38;5;28;01mfor\u001b[39;00m dim, value \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(dimensions, x)}\n\u001b[32m    778\u001b[39m \u001b[38;5;66;03m# Call the wrapped objective function with the named arguments.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m779\u001b[39m objective_value = func(**arg_dict)\n\u001b[32m    781\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m objective_value\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 203\u001b[39m, in \u001b[36mobjective\u001b[39m\u001b[34m(**params)\u001b[39m\n\u001b[32m    200\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m n % \u001b[32m5\u001b[39m == \u001b[32m0\u001b[39m:\n\u001b[32m    201\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m[BO] Trial \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: model=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparams[\u001b[33m'\u001b[39m\u001b[33mmodel_type\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, calib=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparams[\u001b[33m'\u001b[39m\u001b[33mcalibration\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m203\u001b[39m metrics = evaluate_config(params, X_train_bo, y_train_bo,\n\u001b[32m    204\u001b[39m                           objective_mode=\u001b[33m\"\u001b[39m\u001b[33mbenign_tnr\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    205\u001b[39m                           tpr_min=TPR_MIN, lat_cap_s=LAT_CAP_S)\n\u001b[32m    206\u001b[39m TRIALS.append({\u001b[33m\"\u001b[39m\u001b[33mparams\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mdict\u001b[39m(params), \u001b[33m\"\u001b[39m\u001b[33mmetrics\u001b[39m\u001b[33m\"\u001b[39m: metrics})\n\u001b[32m    208\u001b[39m \u001b[38;5;66;03m# lightweight checkpoint to survive crashes\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 162\u001b[39m, in \u001b[36mevaluate_config\u001b[39m\u001b[34m(config, X, Y, objective_mode, tpr_min, lat_cap_s)\u001b[39m\n\u001b[32m    160\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    161\u001b[39m     Xtr2n, Xcaln, Xten = ensure_numeric(Xtr2), ensure_numeric(Xcal), ensure_numeric(Xte)\n\u001b[32m--> \u001b[39m\u001b[32m162\u001b[39m     model.fit(Xtr2n, ytr2, X_val=Xcaln, y_val=ycal)\n\u001b[32m    163\u001b[39m     p_b_cal = model.p_ben(Xcaln)\n\u001b[32m    164\u001b[39m     p_b_val_raw = model.p_ben(Xten)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 39\u001b[39m, in \u001b[36mLGBMWrapper.fit\u001b[39m\u001b[34m(self, X, y_bin, X_val, y_val)\u001b[39m\n\u001b[32m     37\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m: \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m     38\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m X_val \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m y_val \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m39\u001b[39m     \u001b[38;5;28mself\u001b[39m.model.fit(X, y_bin, eval_set=[(X_val, y_val)], eval_metric=\u001b[33m\"\u001b[39m\u001b[33mlogloss\u001b[39m\u001b[33m\"\u001b[39m, callbacks=callbacks)\n\u001b[32m     40\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     41\u001b[39m     \u001b[38;5;28mself\u001b[39m.model.fit(X, y_bin, callbacks=callbacks)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/py312/lib/python3.12/site-packages/lightgbm/sklearn.py:1560\u001b[39m, in \u001b[36mLGBMClassifier.fit\u001b[39m\u001b[34m(self, X, y, sample_weight, init_score, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_metric, feature_name, categorical_feature, callbacks, init_model)\u001b[39m\n\u001b[32m   1557\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1558\u001b[39m             valid_sets.append((valid_x, \u001b[38;5;28mself\u001b[39m._le.transform(valid_y)))\n\u001b[32m-> \u001b[39m\u001b[32m1560\u001b[39m \u001b[38;5;28msuper\u001b[39m().fit(\n\u001b[32m   1561\u001b[39m     X,\n\u001b[32m   1562\u001b[39m     _y,\n\u001b[32m   1563\u001b[39m     sample_weight=sample_weight,\n\u001b[32m   1564\u001b[39m     init_score=init_score,\n\u001b[32m   1565\u001b[39m     eval_set=valid_sets,\n\u001b[32m   1566\u001b[39m     eval_names=eval_names,\n\u001b[32m   1567\u001b[39m     eval_sample_weight=eval_sample_weight,\n\u001b[32m   1568\u001b[39m     eval_class_weight=eval_class_weight,\n\u001b[32m   1569\u001b[39m     eval_init_score=eval_init_score,\n\u001b[32m   1570\u001b[39m     eval_metric=eval_metric,\n\u001b[32m   1571\u001b[39m     feature_name=feature_name,\n\u001b[32m   1572\u001b[39m     categorical_feature=categorical_feature,\n\u001b[32m   1573\u001b[39m     callbacks=callbacks,\n\u001b[32m   1574\u001b[39m     init_model=init_model,\n\u001b[32m   1575\u001b[39m )\n\u001b[32m   1576\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/py312/lib/python3.12/site-packages/lightgbm/sklearn.py:1049\u001b[39m, in \u001b[36mLGBMModel.fit\u001b[39m\u001b[34m(self, X, y, sample_weight, init_score, group, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_group, eval_metric, feature_name, categorical_feature, callbacks, init_model)\u001b[39m\n\u001b[32m   1046\u001b[39m evals_result: _EvalResultDict = {}\n\u001b[32m   1047\u001b[39m callbacks.append(record_evaluation(evals_result))\n\u001b[32m-> \u001b[39m\u001b[32m1049\u001b[39m \u001b[38;5;28mself\u001b[39m._Booster = train(\n\u001b[32m   1050\u001b[39m     params=params,\n\u001b[32m   1051\u001b[39m     train_set=train_set,\n\u001b[32m   1052\u001b[39m     num_boost_round=\u001b[38;5;28mself\u001b[39m.n_estimators,\n\u001b[32m   1053\u001b[39m     valid_sets=valid_sets,\n\u001b[32m   1054\u001b[39m     valid_names=eval_names,\n\u001b[32m   1055\u001b[39m     feval=eval_metrics_callable,  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[32m   1056\u001b[39m     init_model=init_model,\n\u001b[32m   1057\u001b[39m     callbacks=callbacks,\n\u001b[32m   1058\u001b[39m )\n\u001b[32m   1060\u001b[39m \u001b[38;5;66;03m# This populates the property self.n_features_, the number of features in the fitted model,\u001b[39;00m\n\u001b[32m   1061\u001b[39m \u001b[38;5;66;03m# and so should only be set after fitting.\u001b[39;00m\n\u001b[32m   1062\u001b[39m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m   1063\u001b[39m \u001b[38;5;66;03m# The related property self._n_features_in, which populates self.n_features_in_,\u001b[39;00m\n\u001b[32m   1064\u001b[39m \u001b[38;5;66;03m# is set BEFORE fitting.\u001b[39;00m\n\u001b[32m   1065\u001b[39m \u001b[38;5;28mself\u001b[39m._n_features = \u001b[38;5;28mself\u001b[39m._Booster.num_feature()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/py312/lib/python3.12/site-packages/lightgbm/engine.py:297\u001b[39m, in \u001b[36mtrain\u001b[39m\u001b[34m(params, train_set, num_boost_round, valid_sets, valid_names, feval, init_model, keep_training_booster, callbacks)\u001b[39m\n\u001b[32m    295\u001b[39m \u001b[38;5;66;03m# construct booster\u001b[39;00m\n\u001b[32m    296\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m297\u001b[39m     booster = Booster(params=params, train_set=train_set)\n\u001b[32m    298\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m is_valid_contain_train:\n\u001b[32m    299\u001b[39m         booster.set_train_data_name(train_data_name)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/py312/lib/python3.12/site-packages/lightgbm/basic.py:3660\u001b[39m, in \u001b[36mBooster.__init__\u001b[39m\u001b[34m(self, params, train_set, model_file, model_str)\u001b[39m\n\u001b[32m   3658\u001b[39m params.update(train_set.get_params())\n\u001b[32m   3659\u001b[39m params_str = _param_dict_to_str(params)\n\u001b[32m-> \u001b[39m\u001b[32m3660\u001b[39m _safe_call(\n\u001b[32m   3661\u001b[39m     _LIB.LGBM_BoosterCreate(\n\u001b[32m   3662\u001b[39m         train_set._handle,\n\u001b[32m   3663\u001b[39m         _c_str(params_str),\n\u001b[32m   3664\u001b[39m         ctypes.byref(\u001b[38;5;28mself\u001b[39m._handle),\n\u001b[32m   3665\u001b[39m     )\n\u001b[32m   3666\u001b[39m )\n\u001b[32m   3667\u001b[39m \u001b[38;5;66;03m# save reference to data\u001b[39;00m\n\u001b[32m   3668\u001b[39m \u001b[38;5;28mself\u001b[39m.train_set = train_set\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/py312/lib/python3.12/site-packages/lightgbm/basic.py:313\u001b[39m, in \u001b[36m_safe_call\u001b[39m\u001b[34m(ret)\u001b[39m\n\u001b[32m    305\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Check the return value from C API call.\u001b[39;00m\n\u001b[32m    306\u001b[39m \n\u001b[32m    307\u001b[39m \u001b[33;03mParameters\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    310\u001b[39m \u001b[33;03m    The return value from C API calls.\u001b[39;00m\n\u001b[32m    311\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    312\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ret != \u001b[32m0\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m313\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m LightGBMError(_LIB.LGBM_GetLastError().decode(\u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m))\n",
      "\u001b[31mLightGBMError\u001b[39m: Cannot use bagging in GOSS"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "class IF_AP_Wrapper(BaseEstimator):\n",
    "    def __init__(self, **params): self.params, self.model = params, None\n",
    "    def set_params(self, **params): self.params.update(params); return self\n",
    "    def get_params(self, deep=True): return dict(**self.params)\n",
    "    def fit(self, X, y=None):\n",
    "        Xb = X[y == 0] if y is not None else X\n",
    "        self.model = IsolationForest(**self.params).fit(Xb)\n",
    "        return self\n",
    "    def decision_function(self, X):  # higher = more positive\n",
    "        return -self.model.score_samples(X)  # anomaly scores\n",
    "\n",
    "# Combine train+val to let CV compute AP on labeled folds\n",
    "X_cv = np.vstack([X_train, X_val])\n",
    "y_cv = np.concatenate([y_train, y_val])\n",
    "\n",
    "search_space = {\n",
    "    \"n_estimators\":  Integer(100, 800),\n",
    "    \"max_samples\":   Real(0.3, 1.0),\n",
    "    \"contamination\": Real(0.001, 0.02, prior=\"log-uniform\"),\n",
    "    \"max_features\":  Real(0.5, 1.0),\n",
    "}\n",
    "tscv = TimeSeriesSplit(n_splits=4)  # if not time-ordered, a StratifiedKFold would be fine\n",
    "ap_scorer = make_scorer(average_precision_score, needs_threshold=True)\n",
    "\n",
    "bo_est = IF_AP_Wrapper(\n",
    "    n_estimators=300, max_samples=0.7, contamination=0.01, max_features=1.0,\n",
    "    random_state=42, n_jobs=-1\n",
    ")\n",
    "\n",
    "bayes_opt = BayesSearchCV(\n",
    "    bo_est, search_spaces=search_space, n_iter=40, cv=tscv,\n",
    "    scoring=ap_scorer, n_jobs=-1, random_state=42, refit=True\n",
    ")\n",
    "bayes_opt.fit(X_cv, y_cv)\n",
    "\n",
    "print(\"Best (BayesSearchCV) AP:\", bayes_opt.best_score_)\n",
    "print(\"Best params:\", bayes_opt.best_params_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f37698",
   "metadata": {},
   "source": [
    "### 6.1 BO Convergence\n",
    "We plot the **best‑so‑far** AP vs iteration to mirror the “learning curve” style output.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c4d9fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "def plot_bo_convergence(bayes_cv, title=\"Bayesian Optimisation Convergence\"):\n",
    "    # BayesSearchCV may store list if multiple search_spaces; we assume single here\n",
    "    opt_res = bayes_cv.optimizer_results_[0] if isinstance(bayes_cv.optimizer_results_, list) else bayes_cv.optimizer_results_\n",
    "    ys = np.minimum.accumulate(opt_res.func_vals)  # func_vals are losses if scorer minimizes; we used AP (maximize) via scorer\n",
    "    # Our scorer returns AP directly (higher=better). BayesSearchCV maximizes when scorer higher=better,\n",
    "    # but optimizer stores negative? If func_vals look inverted, handle robustly:\n",
    "    f = np.array(opt_res.func_vals)\n",
    "    # Try make \"best so far\" in terms of AP:\n",
    "    ap_series = np.maximum.accumulate(-f) if (f[:3].mean() > 0) else np.maximum.accumulate(f)\n",
    "    plt.figure()\n",
    "    plt.plot(np.arange(1, len(ap_series)+1), ap_series)\n",
    "    plt.xlabel(\"Iteration\")\n",
    "    plt.ylabel(\"Best AP so far\")\n",
    "    plt.title(title); plt.tight_layout()\n",
    "    plt.savefig(\"reports/figures/bo_convergence.png\", dpi=130); plt.close()\n",
    "\n",
    "plot_bo_convergence(bayes_opt, \"BO Convergence — Best AP over iterations\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e9fdb56",
   "metadata": {},
   "source": [
    "## 7. Bayesian Optimisation using Gaussian Processes — `gp_minimize`\n",
    "To mirror the “under the hood” view, we directly optimise a **2‑D slice**:\n",
    "minimise `loss = −AP(val)` over `(n_estimators, max_samples)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c1ae45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "def gp_objective(vec):\n",
    "    ne, ms = int(vec[0]), float(vec[1])\n",
    "    m = IsolationForest(\n",
    "        n_estimators=ne, max_samples=ms, contamination=0.01,\n",
    "        max_features=1.0, random_state=42, n_jobs=-1\n",
    "    ).fit(X_train_benign)\n",
    "    ap = average_precision_score(y_val, -m.score_samples(X_val))\n",
    "    return -ap\n",
    "\n",
    "res_gp = gp_minimize(\n",
    "    gp_objective,\n",
    "    dimensions=[(100, 800), (0.3, 1.0)],\n",
    "    n_calls=20, random_state=42\n",
    ")\n",
    "print(\"GP best loss (−AP):\", res_gp.fun)\n",
    "print(\"GP best params [n_estimators, max_samples]:\", res_gp.x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea690964",
   "metadata": {},
   "source": [
    "## 8. Compare Methods → Select Winner → Final Evaluation\n",
    "Take **best from each method**, refit on **benign train**, and\n",
    "report **validation/test** performance side‑by‑side."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "292f2cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "candidates = []\n",
    "\n",
    "# Random Search winner\n",
    "if best_rs[1] is not None:\n",
    "    candidates.append((\"random_search\", best_rs[1]))\n",
    "\n",
    "# BayesSearchCV winner\n",
    "candidates.append((\"bayes_opt\", bayes_opt.best_params_.copy()))\n",
    "\n",
    "# GP winner (fill remaining params)\n",
    "gp_params = {\"n_estimators\": int(res_gp.x[0]), \"max_samples\": float(res_gp.x[1]),\n",
    "             \"contamination\": 0.01, \"max_features\": 1.0}\n",
    "candidates.append((\"gp_minimize\", gp_params))\n",
    "\n",
    "summary = []\n",
    "for tag, p in candidates:\n",
    "    m = IsolationForest(**{**p, \"random_state\": 42, \"n_jobs\": -1}).fit(X_train_benign)\n",
    "    ap_val = average_precision_score(y_val, -m.score_samples(X_val))\n",
    "    summary.append({\"method\": tag, \"val_AP\": ap_val, **p})\n",
    "    print(f\"{tag}: val AP={ap_val:.4f} params={p}\")\n",
    "\n",
    "summary_df = pd.DataFrame(summary).sort_values(\"val_AP\", ascending=False)\n",
    "display(summary_df.style.format(precision=4))\n",
    "summary_df.to_csv(\"reports/tables/summary_val.csv\", index=False)\n",
    "\n",
    "best_row = summary_df.iloc[0]\n",
    "best_params = {k: best_row[k] for k in [\"n_estimators\",\"max_samples\",\"contamination\",\"max_features\"] if k in best_row}\n",
    "final_model = IsolationForest(**{**best_params, \"random_state\": 42, \"n_jobs\": -1}).fit(X_train_benign)\n",
    "joblib.dump(final_model, MODEL_PATH)\n",
    "\n",
    "print(\"\\nFinal Validation:\")\n",
    "_ = eval_split(\"val_final\", final_model, X_val, y_val)\n",
    "print(\"Final Test:\")\n",
    "_ = eval_split(\"test_final\", final_model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff2ad770",
   "metadata": {},
   "source": [
    "## 9. Thresholds for Later Use (not deploying here)\n",
    "In production you’ll pick τ on anomaly scores to meet an **alert budget**:\n",
    "- τ for **Precision ≥ 90%** (clean analyst queue)\n",
    "- τ for **Benign Specificity ≥ 99%** (minimise benign false alerts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b772bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "def threshold_for_precision(y_true, scores, target_precision=0.90):\n",
    "    p, r, t = precision_recall_curve(y_true, scores)\n",
    "    if len(t) == 0: return None\n",
    "    t_pad = np.concatenate([t, [t[-1]]])\n",
    "    mask = p >= target_precision\n",
    "    if not np.any(mask): return None\n",
    "    idx = np.argmax(mask)\n",
    "    return t_pad[idx]\n",
    "\n",
    "# computing specificity on benign (TNR)\n",
    "def specificity_at_threshold(y_true, scores, tau, benign_label=BENIGN_LABEL):\n",
    "    y_pred_benign = (scores < tau).astype(int)            # 1 = predicted benign\n",
    "    y_true_benign = (y_true == benign_label).astype(int)  # 1 = truly benign\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true_benign, y_pred_benign).ravel()\n",
    "    return tn / (tn + fp) if (tn + fp) > 0 else 0.0\n",
    "\n",
    "\n",
    "def threshold_for_specificity_on_benign(y_true, scores, target_spec=0.99):\n",
    "    for tau in np.unique(scores):\n",
    "        if specificity_at_threshold(y_true, scores, tau) >= target_spec:\n",
    "            return tau\n",
    "    return None\n",
    "\n",
    "scores_val = -final_model.score_samples(X_val)\n",
    "tau_p = threshold_for_precision(y_val, scores_val, target_precision=0.90)\n",
    "tau_s = threshold_for_specificity_on_benign(y_val, scores_val, target_spec=0.99)\n",
    "print(\"τ (Precision≥0.90):\", tau_p, \" | τ (Benign Specificity≥0.99):\", tau_s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "211c34b3",
   "metadata": {},
   "source": [
    "## 10. Discussion (Koehrsen‑style wrap‑up)\n",
    "- **Baseline vs HPO:** Random search provides a quick baseline; BO finds better configs faster\n",
    "   by modelling the objective (AP) and trading off exploration/exploitation.\n",
    "- **Benign‑first angle:** Training on benign only generalises to unknown attacks (no labels needed to fit),\n",
    "   but we still evaluate against labels on validation/test to set a realistic operating point.\n",
    "- **Next steps:** richer features (flows, temporal stats), Safe/Constrained BO (cap FPR / latency), cross‑dataset checks.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a4e78a",
   "metadata": {},
   "source": [
    "## 11. Save Metadata & Repro Bundle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b0ba8f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta = {\n",
    "    \"objective\": \"benign-first; model benign precisely; later flag non-benign via τ\",\n",
    "    \"dataset\": os.path.basename(CSV_PATH),\n",
    "    \"search\": {\"random_search\": True, \"bayessearchcv\": True, \"gp_minimize\": True},\n",
    "    \"artifacts\": {\"model\": MODEL_PATH, \"scaler\": SCALER_PATH, \"trials\": TRIALS_PATH},\n",
    "    \"figures\": [\"reports/figures/pr_val_baseline.png\",\n",
    "                \"reports/figures/pr_test_baseline.png\",\n",
    "                \"reports/figures/bo_convergence.png\"],\n",
    "    \"notes\": \"Notebook follows the format and outputs style of Will Koehrsen's BO notebook (adapted to IF).\",\n",
    "    \"format_references\": [\n",
    "        \"WillKoehrsen/hyperparameter-optimization (GitHub repo)\",\n",
    "        \"Kaggle version of Bayesian HPO of GBM\"\n",
    "    ]\n",
    "}\n",
    "with open(META_PATH, \"w\") as f:\n",
    "    json.dump(meta, f, indent=2)\n",
    "print(\"Saved metadata →\", META_PATH)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
